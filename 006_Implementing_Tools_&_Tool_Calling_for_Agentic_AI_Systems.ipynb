{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dipanjanS/mastering-intelligent-agents-langgraph-workshop-dhs2025/blob/main/Module-1-Introduction-to-Generative-AI-and-Agentic-AI/M1LC6_Implementing_Tools_%26_Tool_Calling_for_Agentic_AI_Systems.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing Tools & Tool Calling for Agentic AI Systems"
      ],
      "metadata": {
        "id": "eS8xcY5jpgQ4"
      },
      "id": "eS8xcY5jpgQ4"
    },
    {
      "cell_type": "markdown",
      "id": "1101434d",
      "metadata": {
        "id": "1101434d"
      },
      "source": [
        "## Tools for Agentic AI Systems\n",
        "\n",
        "In Agentic AI systems, tools are functions that allow the large language model (LLM) to do things it cannot do on its own. These include actions like searching for information, looking up data from a database, performing calculations, or calling APIs.\n",
        "\n",
        "\n",
        "\n",
        "## Tool Calling for Agentic AI Systems\n",
        "\n",
        "Tool calling is what allows the LLM to request a tool when it needs help answering a question. In LangChain, this is done by using the `bind_tools` method. This tells the model what tools are available, how they work, and when to use them when we pass input queries to the LLM.\n",
        "\n",
        "We can also leverage LangGraph and create react agents by passing tools, prompts and LLMs to built-in functions, something we will look at in future demos\n",
        "\n",
        "Remember the LLM will not call the tools for us, we will have to either execute them manually or as we will see in the future live demos, our AI Agents will execute them for us.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem Statement\n",
        "\n",
        "We will be building an Agentic AI system - HealthBuddy, which leverages:\n",
        "\n",
        "- ReAct principles (Reasoning + Acting)\n",
        "- LLM + tools + instructions\n",
        "- Access external information sources (PubMed and Web Search tools)\n",
        "to provide helpful, actionable answers to user health queries â€” including symptom checking, treatment suggestions etc.\n",
        "- Provide appropriate doctor recommendations (using a doctor recommendation tool)\n",
        "\n",
        "The focus in this notebook is to understand how to build custom tools for Agentic AI Systems and connect them to a regular Large Language Model (LLM) to enable it to be able to request tool calls when it needs access to more information to be able to give a better answer to the user query\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### Objective:\n",
        "\n",
        "We want to:\n",
        "\n",
        "- Understand how to design and register custom tools\n",
        "- Enable LLMs to dynamically invoke tools via function/tool calling\n",
        "\n",
        "This notebook focuses on building tools and demonstrating tool-calling as depicted in the following workflow.\n",
        "\n",
        "![](https://i.imgur.com/11KoTnb.png)\n",
        "\n",
        "\n",
        "In the next notebook we will reuse this to build our first Agentic AI System"
      ],
      "metadata": {
        "id": "-Crou2Chq3AW"
      },
      "id": "-Crou2Chq3AW"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain==0.3.27 langchain-openai==0.3.29 langchain-community==0.3.27 arxiv==2.2.0 pymupdf==1.26.3 --quiet"
      ],
      "metadata": {
        "id": "cQQ1g7pGkq-6"
      },
      "id": "cQQ1g7pGkq-6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Necessary Dependencies"
      ],
      "metadata": {
        "id": "BORSQbHHsVsq"
      },
      "id": "BORSQbHHsVsq"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.tools import tool"
      ],
      "metadata": {
        "id": "QQ_lWEMZxSmO"
      },
      "id": "QQ_lWEMZxSmO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Authentication"
      ],
      "metadata": {
        "id": "seFgzKkEsX_o"
      },
      "id": "seFgzKkEsX_o"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "# OpenAI API Key (for chat & embeddings)\n",
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key (https://platform.openai.com/account/api-keys):\\n\")\n",
        "\n",
        "# Tavily API Key (for web search)\n",
        "if not os.environ.get(\"TAVILY_API_KEY\"):\n",
        "    os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Enter your Tavily API key (https://app.tavily.com/home):\\n\")"
      ],
      "metadata": {
        "id": "KbYgtNWOv4P_"
      },
      "id": "KbYgtNWOv4P_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
      ],
      "metadata": {
        "id": "Sfd4PAxHxxRv"
      },
      "id": "Sfd4PAxHxxRv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing Database for Doctor Recommendations Tool\n",
        "\n",
        "In this section, we will create a small, in-memory database that contains information about doctors. This data will be used by our **Doctor Recommendation Tool**, which will help users find the right doctor based on their health query or symptoms.\n",
        "\n",
        "The database includes a list of doctors along with their:\n",
        "- Name\n",
        "- Specialization (e.g., Dermatology, Pediatrics, Cardiology)\n",
        "- Location\n",
        "- Availability\n",
        "- Contact information\n",
        "\n",
        "We are using a simple Python list of dictionaries to store the doctor data. This keeps it easy to understand and modify. In a real-world application, this would typically be replaced by a backend database like PostgreSQL, MongoDB, or an external API.\n",
        "\n",
        "We will build a tool later on to use this data to recommend doctors based on the user's needs â€” for example, suggesting a pediatrician for a childâ€™s fever or a cardiologist for chest pain."
      ],
      "metadata": {
        "id": "yOuACuleCIjE"
      },
      "id": "yOuACuleCIjE"
    },
    {
      "cell_type": "code",
      "source": [
        "# loading our doctors dataset\n",
        "doctors_db = [\n",
        "    {\"name\": \"Dr. Janet Dyne\", \"specialization\": \"Endocrinology (Diabetes Care)\", \"available_timings\": \"10:00 AM - 1:00 PM\", \"location\": \"City Health Clinic\", \"contact\": \"janet.dyne@healthclinic.com\"},\n",
        "    {\"name\": \"Dr. Don Blake \", \"specialization\": \"Cardiology (Heart Specialist)\", \"available_timings\": \"2:00 PM - 5:00 PM\", \"location\": \"Metro Cardiac Center\", \"contact\": \"don.blake@metrocardiac.com\"},\n",
        "    {\"name\": \"Dr. Susan D'Souza\", \"specialization\": \"Oncology (Cancer Care)\", \"available_timings\": \"11:00 AM - 2:00 PM\", \"location\": \"Hope Cancer Institute\", \"contact\": \"susan.dsouza@hopecancer.org\"},\n",
        "    {\"name\": \"Dr. Matt Murdock\", \"specialization\": \"Psychiatry (Mental Health)\", \"available_timings\": \"4:00 PM - 7:00 PM\", \"location\": \"Mind Care Center\", \"contact\": \"matt.murdock@mindcare.com\"},\n",
        "    {\"name\": \"Dr. Dinah Lance\", \"specialization\": \"General Physician\", \"available_timings\": \"9:00 AM - 12:00 PM\", \"location\": \"Downtown Medical Center\", \"contact\": \"dinah.lance@downtownmed.com\"}\n",
        "]"
      ],
      "metadata": {
        "id": "hmVstsSUCj4s"
      },
      "id": "hmVstsSUCj4s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Tools for AI Agent\n",
        "\n",
        "In this section, we will define the tools that our AI Agent will use to perform specific tasks.\n",
        "\n",
        "LangChain makes it easy to create and register tools using the `Tool` class. A tool includes:\n",
        "- A name and description\n",
        "- The python function to be called\n",
        "- An input schema that tells the model what arguments it can use\n",
        "\n",
        "When tools are defined properly, they help the model solve more complex problems by letting it take actions and use external data. This makes the system more useful and reliable.\n",
        "\n",
        "### ðŸ§ª Example\n",
        "```python\n",
        "from langchain.tools import tool\n",
        "\n",
        "@tool\n",
        "def search_web(query: str) -> str:\n",
        "    \"\"\"Get live information for user queries from the web.\"\"\"\n",
        "    # assuming we have a google_search function implemented to search on google\n",
        "    return google_search(query)\n",
        "```\n",
        "\n",
        "These tools will allow the agent to retrieve information from the external environment, as well as recommend doctors from our in-memory doctor database.\n",
        "\n",
        "The goal is to modularize the logic for different types of tasks into reusable components that can be invoked by the LLM when needed. These include:\n",
        "\n",
        "- A **Web Search Tool** that queries the web to simulate general online web search\n",
        "- A **arXiv Search Tool** that retrieves information from arXiv for research-grade medical content\n",
        "- A **Doctor Recommendation Tool** that finds suitable doctors based on user symptoms or needs\n",
        "\n",
        "This tool-based setup is essential for enabling agentic behavior, where the LLM reasons through a problem, decides which action to take, and requests to call the right tools to gather more information or perform a task.\n"
      ],
      "metadata": {
        "id": "lLmG5MF4_f_t"
      },
      "id": "lLmG5MF4_f_t"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
        "from langchain_community.retrievers import ArxivRetriever\n",
        "\n",
        "# Tool for web search on general health topics\n",
        "# Tavily Web Search\n",
        "tavily_search = TavilySearchAPIWrapper()\n",
        "\n",
        "@tool\n",
        "def search_web(query: str) -> list:\n",
        "    \"\"\"Search the web for a query. Useful for getting general information or upto date information about healthcare topics.\"\"\"\n",
        "    # Perform web search on the internet\n",
        "    results = tavily_search.raw_results(query=query, max_results=5, search_depth='advanced',\n",
        "                                        include_answer=False, include_raw_content=True)\n",
        "    docs = results['results']\n",
        "    docs = [doc for doc in docs if doc.get(\"raw_content\") is not None]\n",
        "    docs = ['## Title\\n'+doc['title']+'\\n\\n'+'## Content\\n'+doc['raw_content']+'\\n\\n'+'##Source\\n'+doc['url'] for doc in docs]\n",
        "    return docs\n",
        "\n",
        "\n",
        "# Tool for arXiv Search\n",
        "# arxiv search retriever\n",
        "arxiv_retriever = ArxivRetriever(\n",
        "    top_k_results=3,\n",
        "    get_full_documents=True,\n",
        "    doc_content_chars_max=20000\n",
        ")\n",
        "@tool\n",
        "def search_arxiv(query: str) -> list:\n",
        "    \"\"\"Search arXiv for scientific articles related to the query.\"\"\"\n",
        "    try:\n",
        "        results = arxiv_retriever.invoke(query)\n",
        "        if results:\n",
        "            articles = ['## Title\\n'+doc.metadata['Title']+'\\n\\n'+'## Summary\\n'+doc.metadata['Summary']+'\\n\\n'+'##Content\\n'+doc.page_content for doc in results]\n",
        "            return articles\n",
        "        else:\n",
        "            return [\"No articles found for the given query.\"]\n",
        "    except Exception as e:\n",
        "        return [f\"Error fetching arXiv articles: {str(e)}\"]\n",
        "\n",
        "\n",
        "# Tool for recommending a doctor based on user symptoms or query\n",
        "@tool\n",
        "def recommend_doctor(query: str) -> dict:\n",
        "    \"\"\"Recommend the most suitable doctor based on the user's symptoms.\"\"\"\n",
        "    doctors_list = str(doctors_db)\n",
        "    # Use LLM reasoning to choose the most appropriate doctor based on the query\n",
        "    prompt = f\"\"\"You are an assistant helping recommend a doctor based on patient's health issues.\n",
        "\n",
        "                 Here is the list of available doctors:\n",
        "                {doctors_list}\n",
        "\n",
        "                Given the user's query: \"{query}\"\n",
        "\n",
        "                Choose the most suitable doctor from the list. Only pick one doctor.\n",
        "                Return only the selected doctor's information in JSON format (no markdown).\n",
        "                If not sure, recommend the General Physician.\n",
        "              \"\"\"\n",
        "\n",
        "    response = llm.invoke(prompt)\n",
        "    return {\"recommended_doctor\": response.content}"
      ],
      "metadata": {
        "id": "vd5MS0gX-TCD"
      },
      "id": "vd5MS0gX-TCD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing out our Tools\n",
        "\n",
        "You can just call the above tools manually by using the `.invoke(...)` function with the necessary inputs.\n",
        "\n",
        "The following code shows some example queries and outputs on calling these tools"
      ],
      "metadata": {
        "id": "5H01EYNoBdmI"
      },
      "id": "5H01EYNoBdmI"
    },
    {
      "cell_type": "code",
      "source": [
        "results = search_web.invoke('Popular treatments in Diabetes')\n",
        "print(len(results))\n",
        "print(results[0][:3000])"
      ],
      "metadata": {
        "id": "kc41UkixeAHM"
      },
      "id": "kc41UkixeAHM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = search_arxiv.invoke('treatments in Diabetes')\n",
        "print(len(results))\n",
        "print(results[0][:3000])"
      ],
      "metadata": {
        "id": "wjIO9ErVAskm"
      },
      "id": "wjIO9ErVAskm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = recommend_doctor.invoke('Treatments for Diabetes')\n",
        "print(result)"
      ],
      "metadata": {
        "id": "z35ew2OSC_-O"
      },
      "id": "z35ew2OSC_-O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explore LLM tool calling with custom tools\n",
        "\n",
        "An agent is basically an LLM which has the capability to automatically call relevant functions to perform complex or tool-based tasks based on input human prompts.\n",
        "\n",
        "Tool calling also popularly known as function calling is the ability to reliably enable such LLMs to call external tools and APIs.\n",
        "\n",
        "We will leverate the custom tools we created earlier in the previous section and try to see if the LLM can automatically call the right tools based on input prompts"
      ],
      "metadata": {
        "id": "bIOhB430gpW9"
      },
      "id": "bIOhB430gpW9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tool calling for LLMs"
      ],
      "metadata": {
        "id": "4Y26Ohn3P54j"
      },
      "id": "4Y26Ohn3P54j"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tool calling allows a model to respond to a given prompt by generating output that matches a user-defined schema. While the name implies that the model is performing some action, this is actually not the case! The model is coming up with the arguments to a tool, and actually running the tool (or not) is up to the user or agent defined by the user.\n",
        "\n",
        "Many LLM providers, including Anthropic, Cohere, Google, Mistral, OpenAI, and others, support variants of a tool calling feature. These features typically allow requests to the LLM to include available tools and their schemas, and for responses to include calls to these tools.\n",
        "\n",
        "For example, if a user asks a question that requires a search or data lookup, the model can decide to call a specific tool with a tool call request.\n",
        "\n",
        "Tool calling in LangChain works by:\n",
        "1. Registering defined tool functions using `@tool` decorator\n",
        "2. Binding the tools to the model using `llm.bind_tools([tool1, tool2, ...])`\n",
        "3. Passing a user query to the bound model\n",
        "4. Letting the model decide whether to use a tool or respond directly\n",
        "\n",
        "This setup lets the model behave more like an agent that can take actions, observe results, and continue the conversation intelligently.\n",
        "\n",
        "By using `bind_tools`, we give the LLM the ability to understand what tools are available and make requests to use them only when needed.\n",
        "\n",
        "### ðŸ§ª Example\n",
        "```python\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "\n",
        "llm = AzureChatOpenAI(model=\"gpt-4o-mini\")\n",
        "llm_with_tools = llm.bind_tools([search_web])\n",
        "\n",
        "response = llm_with_tools.invoke(\"treatments for diabetes?\")\n",
        "```"
      ],
      "metadata": {
        "id": "1nACq0NgL5yM"
      },
      "id": "1nACq0NgL5yM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tool Call Requests\n",
        "\n",
        "LLMs will not call and execute the tools for you directly but will request tool calls based on reasoning on the input user query if they feel that they do not have enough information to answer the question directly.\n",
        "\n",
        "To experiment with this, let's first define our tools and bind them to our LLM"
      ],
      "metadata": {
        "id": "M3EVLljBHLHn"
      },
      "id": "M3EVLljBHLHn"
    },
    {
      "cell_type": "code",
      "source": [
        "# List of all tools that the LLM should be aware of\n",
        "# These tools were defined earlier using the @tool decorator\n",
        "tools = [search_web, search_arxiv, recommend_doctor]\n",
        "\n",
        "# Bind the tools to the LLM so it can request tool calls when needed\n",
        "# This enables tool calling functionality in LangChain\n",
        "llm_with_tools = llm.bind_tools(tools=tools)"
      ],
      "metadata": {
        "id": "zOoAt9VVHcZP"
      },
      "id": "zOoAt9VVHcZP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can test out these prompts using out LLM with tools"
      ],
      "metadata": {
        "id": "Dsze8yBOHfsN"
      },
      "id": "Dsze8yBOHfsN"
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = [\n",
        "    \"treatments available for diabetes\",\n",
        "    \"Research papers on diabetes treatments\",\n",
        "    \"What doctor could I visit for diabetes\",\n",
        "    \"Explain what is diabetes in simple terms\"\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "for prompt in prompts:\n",
        "    result = llm_with_tools.invoke(prompt)\n",
        "    results.append(result)"
      ],
      "metadata": {
        "id": "BRHkkUdcHhb6"
      },
      "id": "BRHkkUdcHhb6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observe that:\n",
        "\n",
        "- If the LLM can answer the question directly, the response will be present in `result.content`\n",
        "- If the LLM can't answer the question directly, the response will be empty but will contain one or more tool call requests in `result.tool_calls`"
      ],
      "metadata": {
        "id": "OKhg7aAbH4Eb"
      },
      "id": "OKhg7aAbH4Eb"
    },
    {
      "cell_type": "code",
      "source": [
        "for result in results:\n",
        "    # If the model gave a direct response without needing a tool\n",
        "    if result.content:\n",
        "        print('No tool call was needed')\n",
        "        print('Direct LLM Response:', result.content)\n",
        "\n",
        "    # If the model decided that a tool should be called\n",
        "    if result.tool_calls:\n",
        "        print('LLM needs to call tools')\n",
        "        print(result.tool_calls)\n",
        "\n",
        "    print()"
      ],
      "metadata": {
        "id": "9D8xAHMCHzLv"
      },
      "id": "9D8xAHMCHzLv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tool Call Responses with Manual Tool Calling\n",
        "\n",
        "While an Agentic Framework like LangChain or LangGraph can leverage AI Agents themselves to handle tool call requests by calling them automatically and getting tool call results (to further feed it to the LLM for more reasoning), here we will call these tool call requests manually just to show how the results would look like.\n",
        "\n",
        "In future demos the AI Agents will handle this automatically.\n",
        "\n",
        "We start off by creating a mapping between the tool call names (strings) and the actual tool functions (python function names)"
      ],
      "metadata": {
        "id": "1qDfoKCyJUCk"
      },
      "id": "1qDfoKCyJUCk"
    },
    {
      "cell_type": "code",
      "source": [
        "# create a mapping between tool call request name and the actual tool call function\n",
        "tool_mapper = {\n",
        "    \"search_web\": search_web,\n",
        "    \"search_arxiv\": search_arxiv,\n",
        "    \"recommend_doctor\": recommend_doctor\n",
        "}"
      ],
      "metadata": {
        "id": "EJ_gvizxJri8"
      },
      "id": "EJ_gvizxJri8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you inspect the tool call requests for any input prompt,\n",
        "we have the tool name and the input arguments which will need to be extracted and then we will need to call the actual tool with the input arguments\n",
        "\n",
        "For example based on the following tool call request, we would need to call:\n",
        "\n",
        "`search_web.invoke(query='treatments available for diabetes')`"
      ],
      "metadata": {
        "id": "bh9RUTNsK9OM"
      },
      "id": "bh9RUTNsK9OM"
    },
    {
      "cell_type": "code",
      "source": [
        "# check out a sample tool call request\n",
        "results[0].tool_calls"
      ],
      "metadata": {
        "id": "1C07HUmHKJAZ"
      },
      "id": "1C07HUmHKJAZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can easily automate this by extracting the tool call request `name` and `args` and invoking the actual python tool function matching the `name` with the input arguments (`args`)"
      ],
      "metadata": {
        "id": "M0qFBjOvLYQw"
      },
      "id": "M0qFBjOvLYQw"
    },
    {
      "cell_type": "code",
      "source": [
        "for result in results:\n",
        "    tool_call_requests = result.tool_calls\n",
        "    for tool_call in tool_call_requests:\n",
        "        # Get the actual tool function from the name using the mapping\n",
        "        selected_tool = tool_mapper[tool_call[\"name\"]]\n",
        "\n",
        "        # Execute the tool with the provided arguments from the LLM\n",
        "        print(f\"Calling tool: {tool_call['name']}\")\n",
        "        tool_output = selected_tool.invoke(tool_call[\"args\"])\n",
        "        print(tool_output)\n",
        "        print()\n"
      ],
      "metadata": {
        "id": "kODS4cVHJ1ob"
      },
      "id": "kODS4cVHJ1ob",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the upcoming hands-on demo you will see how to connect LLMs, tools and instruction prompts together to automate this and build your first Agentic AI System with Tool-Use!"
      ],
      "metadata": {
        "id": "ZCutQe7xLmd_"
      },
      "id": "ZCutQe7xLmd_"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}