{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8usx0A/KSdISRNdH0LfAN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dipanjanS/mastering-intelligent-agents-langgraph-workshop-dhs2025/blob/main/Module-3-Context-Engineering-for-Agentic-AI-Systems/M3LC1_Building_Agentic_AI_Systems_with_Pre_built_MCP_Servers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building Agentic AI Systems with Pre-built MCP Servers\n",
        "\n",
        "In this notebook, we explore how to build an **Agentic AI system** by combining a **pre-built MCP server** with LangGraph's AI Agent capabilities.\n",
        "\n",
        "The system demonstrates how an LLM-based agent can use external tools—served via the [Model Context Protocol (MCP)](https://modelcontextprotocol.io/)—to complete complex tasks.\n",
        "\n",
        "We use the `markitdown-mcp` server as a concrete example, which exposes a document conversion tool (`convert_to_markdown`) over MCP. The agent uses this tool to extract content from external sources (e.g., web articles) and generate structured markdown reports. The architecture diagram is shown below.\n",
        "\n",
        "![](https://i.imgur.com/ielptGR.png)\n",
        "\n",
        "### Key Concepts Covered:\n",
        "- Setting up and launching a pre-built MCP server (`markitdown-mcp`)\n",
        "- Using `langchain_mcp_adapters` to connect MCP tools with LangChain agents\n",
        "- Building a ReAct-style agent using `create_react_agent` from LangGraph\n",
        "- Running an end-to-end task: convert and summarize content from a URL\n",
        "- Saving the agent's output as a local markdown file (`document.md`)\n",
        "\n",
        "This notebook demonstrates how MCP simplifies tool integration for agents, allowing LLMs to reason, act, and interact with external systems through a standard interface, without writing custom wrappers and tools.\n"
      ],
      "metadata": {
        "id": "uwq9MXorjrxE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Dependencies"
      ],
      "metadata": {
        "id": "p4s54_qjjopC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install markitdown-mcp==0.0.1a4 langgraph==0.6.5 langchain==0.3.27 langchain-openai==0.3.29 langchain-community==0.3.27 --quiet"
      ],
      "metadata": {
        "id": "lUSCSC6NRDkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-mcp-adapters==0.1.9 --quiet"
      ],
      "metadata": {
        "id": "KcxMPGm3_wuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deploy Pre-built Markitdown MCP Server"
      ],
      "metadata": {
        "id": "e5eIJ1SVj0py"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup markitdown-mcp --http --host 127.0.0.1 --port 8011 > server_output.log 2>&1 &"
      ],
      "metadata": {
        "id": "RbVhU_yag_F8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://i.imgur.com/cHB4UzQ.png)"
      ],
      "metadata": {
        "id": "CffIsRXrg2_2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get OpenAI Key Environment File"
      ],
      "metadata": {
        "id": "e89SAepwhZrD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1dyWtBg0RCg_WqzsuMWhvJwrN8_GGDmbI"
      ],
      "metadata": {
        "id": "WrvSnmWbhifm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add your OpenAI Key in the Environment File\n",
        "\n",
        "Open up the `.env` file and enter your OpenAI key in the place shown below and then save the file\n",
        "\n",
        "![](https://i.imgur.com/ThkufIW.png)"
      ],
      "metadata": {
        "id": "CRSi1D-Bh0we"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create your Client Content Analyst & Report Generator AI Agent"
      ],
      "metadata": {
        "id": "DwVc42mgj6TM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile client_agent.py\n",
        "\n",
        "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "import asyncio\n",
        "from dotenv import load_dotenv\n",
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "\n",
        "load_dotenv()\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "async def main():\n",
        "    client = MultiServerMCPClient({\n",
        "        \"markitdown\": {\n",
        "            \"url\": \"http://localhost:8011/mcp\",\n",
        "            \"transport\": \"streamable_http\"\n",
        "        }\n",
        "\n",
        "    })\n",
        "\n",
        "    tools = await client.get_tools()\n",
        "    print(\"Discovered tools:\", [tool.name for tool in tools])\n",
        "\n",
        "    AGENT_PROMPT_TXT = \"\"\"Act as a helpful assistant.\n",
        "    Use the tools available to extract information as necessary.\n",
        "    Summarize the key aspects and provide an executive report.\n",
        "    \"\"\"\n",
        "\n",
        "    SYS_PROMPT = SystemMessage(content=AGENT_PROMPT_TXT)\n",
        "    agent = create_react_agent(model=llm, tools=tools, prompt=SYS_PROMPT)\n",
        "\n",
        "    # Sample queries\n",
        "    print('\\nUsing capabilities for document extraction:')\n",
        "    source = \"https://www.ibm.com/think/topics/agentic-ai\"\n",
        "    prompt = \"\"\"Create a report on the following article\n",
        "                Source: {src}\"\"\"\n",
        "    prompt = prompt.format(src=source)\n",
        "    result = await agent.ainvoke({\"messages\": [{\"role\": \"user\", \"content\": prompt}]})\n",
        "    with open(\"document.md\", 'w') as f:\n",
        "        f.write(result[\"messages\"][-1].content)\n",
        "    print('Report has been created')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())"
      ],
      "metadata": {
        "id": "Xu-FxE5kQzLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the Agent\n",
        "\n",
        "We can run the agent as shown in the following snapshot in the terminal\n",
        "\n",
        "![](https://i.imgur.com/GuDpKOU.png)"
      ],
      "metadata": {
        "id": "MKKkvIEjiV3e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then you can open up the `document.md` report file created by the agent as shown here.\n",
        "\n",
        "![](https://i.imgur.com/gYKtyaL.png)"
      ],
      "metadata": {
        "id": "1CVefn0ZioPL"
      }
    }
  ]
}